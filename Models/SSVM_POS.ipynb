{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f931925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dlib\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcb0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class for solving the SSVM problem\n",
    "class POSTaggingProblem:\n",
    "    C = 1\n",
    "    \n",
    "    #initializing the problem\n",
    "    def __init__(self, samples, labels, L, K, d):\n",
    "        self.L = L\n",
    "        self.K = K\n",
    "        self.d = d\n",
    "        self.Niter = 10\n",
    "        self.num_samples = len(samples)\n",
    "        self.num_dimensions = 1 + (L - 1) * (K * d + 1) + (K - 1) * d + d\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.loss_for_loop = True\n",
    "    #returns a feature vector given an input sample and its label\n",
    "    def make_psi(self, x, label):\n",
    "        psi = np.zeros(self.num_dimensions)\n",
    "        psi[0] = 1.0  # The bias\n",
    "        for iL in range(self.L):\n",
    "            i = label[iL] if iL < len(label) else self.K - 1  \n",
    "            start = 1 + iL * (self.K * self.d + 1) + i * self.d\n",
    "            if iL < len(x): \n",
    "                psi[start:start + self.d] = x[iL][:self.d]\n",
    "        return dlib.vector(psi)\n",
    "    \n",
    "    #returns a feature vector for a given sample with its true label:\n",
    "    def get_truth_joint_feature_vector(self, idx):\n",
    "        return self.make_psi(self.samples[idx], self.labels[idx])\n",
    "    \n",
    "    #finds most violating classes and calculates loss:\n",
    "    def separation_oracle(self, idx, current_solution):\n",
    "        samp = self.samples[idx]\n",
    "        psi = dlib.vector()\n",
    "        psi.resize(self.num_dimensions)\n",
    "        max1 = -1e10\n",
    "        max_scoring_label = [0] * self.L\n",
    "        for iL in range(self.L):\n",
    "            for i in range(self.K):\n",
    "                tmp_label = list(self.labels[idx])\n",
    "                tmp_label[iL] = i\n",
    "                tmp_psi = self.make_psi(samp, tmp_label)\n",
    "                score1 = dlib.dot(current_solution, tmp_psi)\n",
    "                loss1 = 0.0\n",
    "                if self.loss_for_loop:\n",
    "                    for j in range(self.L):\n",
    "                        if self.labels[idx][j] != tmp_label[j]:\n",
    "                            loss1 += 1.0\n",
    "                if max1 < score1 + loss1:\n",
    "                    max1 = score1 + loss1\n",
    "                    loss = loss1\n",
    "                    max_scoring_label[iL] = i\n",
    "                    psi = tmp_psi\n",
    "        return loss, psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3ce156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a subset of the data \n",
    "tagged_sentences = treebank.tagged_sents()[:1000]\n",
    "\n",
    "#Function to simplify tags for decreased complexity\n",
    "def simplify_tag(tag):\n",
    "    if tag.startswith('N'): return \"NOUN\"\n",
    "    elif tag.startswith('V'): return \"VERB\"\n",
    "    elif tag.startswith('J'): return \"ADJ\"\n",
    "    else: return \"OTHER\"\n",
    "    \n",
    "#Preprocessing the sentences\n",
    "def preprocess_sentence(tagged_sentence):\n",
    "    words, tags = zip(*tagged_sentence)\n",
    "    words = [word.lower() for word in words]\n",
    "    tags = [simplify_tag(tag) for tag in tags]\n",
    "    return words, tags\n",
    "\n",
    "#Padding the list \n",
    "def pad_to_length(lst, length, padding_element):\n",
    "    if len(lst) < length:\n",
    "        return lst + [padding_element] * (length - len(lst))\n",
    "    else:\n",
    "        return lst\n",
    "\n",
    "\n",
    "sentences, labels = zip(*[preprocess_sentence(sentence) for sentence in tagged_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca683fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words (including padding): 5026\n",
      "Number of unique tags (including padding): 5\n",
      "Window size: 7\n",
      "Dimensions: 100\n"
     ]
    }
   ],
   "source": [
    "# Training the Word2Vec model\n",
    "sentences = [list(sentence) for sentence in sentences]\n",
    "model = Word2Vec(sentences, min_count=1, vector_size=100)\n",
    "\n",
    "#Converting words to vectors using word2vec\n",
    "def word_to_vec(word, model):\n",
    "    return model.wv[word] if word in model.wv else np.zeros(model.vector_size)\n",
    "\n",
    "#Building a vocab of all the words and list for labels\n",
    "vocabulary = list(set(word for sentence in sentences for word in sentence))\n",
    "vocabulary.append('PADDING')\n",
    "all_tags = list(set(tag for tags in labels for tag in tags))\n",
    "all_tags.append('PADDING')\n",
    "\n",
    "K = len(all_tags)\n",
    "L = 7  # Window size \n",
    "d = model.vector_size\n",
    "\n",
    "print('Number of unique words (including padding):', len(vocabulary))\n",
    "print('Number of unique tags (including padding):', len(all_tags))\n",
    "print('Window size:', L)\n",
    "print('Dimensions:', d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10cb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_padded = [pad_to_length(sentence, L, 'PADDING') for sentence in sentences]\n",
    "labels_padded = [pad_to_length(tags, L, 'PADDING') for tags in labels]\n",
    "\n",
    "features = [[word_to_vec(word, model) for word in sentence] for sentence in sentences_padded]\n",
    "label_numbers = [[all_tags.index(tag) if tag != 'PADDING' else -1 for tag in label] for label in labels_padded]\n",
    "\n",
    "split = int(len(features) * 0.8)\n",
    "train_features = features[:split]\n",
    "train_labels = label_numbers[:split]\n",
    "test_features = features[split:]\n",
    "test_labels = label_numbers[split:]\n",
    "\n",
    "train_features_windows = [sentence[i:i + L] for sentence in train_features for i in range(len(sentence) - L + 1)]\n",
    "train_labels_windows = [labels[i:i + L] for labels in train_labels for i in range(len(labels) - L + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7aa24c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and solving the SSVM problem...\n",
      "SSVM problem solved.\n",
      "Training time: 906.6982996463776 seconds\n"
     ]
    }
   ],
   "source": [
    "#Solving the SSVM Problem\n",
    "print('Creating and solving the SSVM problem...')\n",
    "start_train_time = time.time()\n",
    "problem = POSTaggingProblem(train_features_windows, train_labels_windows, L, K, d)\n",
    "solution = dlib.solve_structural_svm_problem(problem)\n",
    "end_train_time = time.time()\n",
    "print('SSVM problem solved.')\n",
    "\n",
    "print(f'Training time: {end_train_time - start_train_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edfee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "Progress: [200/200]\n",
      "Test time: 5.975387811660767 seconds\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "\n",
    "print('Evaluating the model...')\n",
    "start_test_time = time.time()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "total_tags = 0\n",
    "predictions = []\n",
    "\n",
    "for idx, sentence_features in enumerate(test_features):\n",
    "    predicted_labels = []\n",
    "    \n",
    "    scores = []\n",
    "    for tag_index in range(K):\n",
    "        label_sequence = [tag_index]\n",
    "        scores.append(dlib.dot(solution, problem.make_psi([sentence_features[0]], label_sequence)))\n",
    "    predicted_labels.append(scores.index(max(scores)))\n",
    "\n",
    "    for i in range(1, len(sentence_features) - 1):\n",
    "        window_features = sentence_features[i-1:i+2]\n",
    "        scores = []\n",
    "        for tag_index in range(K):\n",
    "            label_sequence = [0, tag_index, 0]  # Now the target label is in the middle of the label sequence\n",
    "            scores.append(dlib.dot(solution, problem.make_psi(window_features, label_sequence)))\n",
    "        predicted_labels.append(scores.index(max(scores)))\n",
    "\n",
    "    scores = []\n",
    "    for tag_index in range(K):\n",
    "        label_sequence = [tag_index]\n",
    "        scores.append(dlib.dot(solution, problem.make_psi([sentence_features[-1]], label_sequence)))\n",
    "    predicted_labels.append(scores.index(max(scores)))\n",
    "\n",
    "    predictions.append(predicted_labels)\n",
    "    \n",
    "    print('Progress: [{0}/{1}]'.format(idx + 1, len(test_features)), flush=True, end='\\r')\n",
    "\n",
    "    # Updating counts for accuracy calc\n",
    "    actual_labels = test_labels[idx][:len(sentence_features)]  # Consider all labels in the sentence\n",
    "    for predicted, actual in zip(predicted_labels, actual_labels):\n",
    "        if actual != -1:\n",
    "            total_predictions += 1\n",
    "            if predicted == actual:\n",
    "                correct_predictions += 1\n",
    "\n",
    "end_test_time = time.time()\n",
    "print(f'\\nTest time: {end_test_time - start_test_time} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a50a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.20567510950295181\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracy\n",
    "if total_predictions != 0:\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print('\\nAccuracy:', accuracy)\n",
    "else:\n",
    "    print('\\nNo predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea3b0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: terms were n't disclosed *-1 .\n",
      "Ground truth: NOUN VERB OTHER VERB OTHER OTHER PADDING\n",
      "Prediction: NOUN NOUN NOUN OTHER NOUN NOUN OTHER\n"
     ]
    }
   ],
   "source": [
    "# Random test example to print\n",
    "example_index = random.randint(0, len(test_features) - 1)\n",
    "example_sentence = sentences[split:][example_index]\n",
    "example_ground_truth = test_labels[example_index]\n",
    "example_prediction = predictions[example_index]\n",
    "\n",
    "print('Example sentence:', ' '.join(example_sentence))\n",
    "print('Ground truth:', ' '.join([all_tags[label] if label != -1 else 'PADDING' for label in example_ground_truth]))\n",
    "print('Prediction:', ' '.join([all_tags[label] if label != -1 else 'PADDING' for label in example_prediction]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a3fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
